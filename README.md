# AI Image Detector: Классификация изображений на реальные и сгенерированные

### Цель проекта

**Бизнес-цель**: Снизить распространение дезинформации и вредоносного контента на цифровых платформах путем автоматического обнаружения изображений, созданных с помощью искусственного интеллекта.

**Техническая цель**: Создать и развернуть API-сервис, который принимает на вход изображение и возвращает его класс (Real, AI-generated, Deepfake) и степень уверенности модели.

### Целевые метрики

#### Метрики качества модели
- **Recall для класса"Deepfake": ≥ 97%**. Какой процент всех фейковых изображений мы смогли обнаружить
- **F1-Score** ≥ 0.96

#### Технические метрики
- **Latency**: ≤ 150 мс для 95-го перцентиля запросов. Для классификации изображений это критично, чтобы не замедлять загрузку контента для пользователя.
- **Доля неуспешных запросов**: ≤ 1 %.
- **Throughput**: сервис должен обрабатывать не менее 50 запросов в секунду (RPS) на одном инстансе.
- **Resource Usage**: Утилизация CPU/GPU не должна превышать 75% от выделенных лимитов в среднем за час, чтобы обеспечить запас для пиковых нагрузок

### Набор данных

В проекте используется датасет "OpenDeepfake", доступный на Hugging Face.
- Ссылка: [prithivMLmods/OpenDeepfake-Preview](https://huggingface.co/datasets/prithivMLmods/OpenDeepfake-Preview)
- Объем: 20,000 изображений.
Структура: Данные разделены на обучающую (train) и тестовую (test) выборки.
- Классы:
    - Real: Настоящие, необработанные фотографии людей и сцен.
    - Deepfake: Реальные фотографии, в которые были внесены изменения с помощью ИИ, чаще всего — замена или модификация лиц.

### План экспериментов

1. Baseline модель. Дообучение mobilenet
3. Увеличение качества работы модели. Использовать аугментации, другие архитектуры и др
4. Оптимизация для продакшена: Сжатие и ускорение модели (например, квантизация или дистилляция), нагрузочное тестирование.
5. Развертывание модели

### Поддержка DVC

1. Создайте аккаунт на DagsHub.
2. Настройте аутентификацию. DagsHub использует специальный токен.

```
export AWS_ACCESS_KEY_ID=<your_dagshub_token>
export AWS_SECRET_ACCESS_KEY=<your_dagshub_token>
```

### Логирование в MLFlow

1. Реализовано логирование в mlflow
2. Все запуски логируются локально в директорию `mlruns/`. Чтобы просмотреть результаты в веб-интерфейсе, выполните команду в корне проекта: `mlflow ui`
3. [Также эксперименты можно просматривать в DagsHub](https://dagshub.com/TrandeLik/mlops/experiments)
4. Для воспроизведения логирования в DagsHub нужно выполнить следующие команды:

```
export MLFLOW_TRACKING_URI=https://dagshub.com/TrandeLik/mlops.mlflow
export MLFLOW_TRACKING_USERNAME=<your_username>
export MLFLOW_TRACKING_PASSWORD=<your_dagshub_token>
```

### Docker

1.  Убедитесь, что у вас есть модель. Если вы еще не скачали модель, выполните:  `dvc pull`
2.  Соберите Docker-образ: `docker build -t ai-detector:v1 .`
3. Скрипт `src/predict.py` внутри контейнера принимает на вход папку с изображениями и сохраняет предсказания в CSV-файл. Подготовьте входные данные, например, в папке `local_input` (в ней уже находятся примеры) изображений. Создайте папку для выхода (например, `local_output`).
4. Запустите контейнер для получения предсказаний:

```
docker run --rm -v "$(pwd)/local_input:/app/input" -v "$(pwd)/local_output:/app/output" ai-detector:v1 --input_path /app/input --output_path /app/output/new_predictions.csv
```

5. В `local_output/new_predictions.csv` будут храниться предсказания, формат можно посмотреть в файле-примере (`local_output/predictions.csv`). Отметим, что в целях безопасности у docker-а нет прав на редактирование существующих файлов, поэтому следует либо удалить `predictions.csv`, либо указывать в команде другое название файла

### TorchServe

1.  Создание архива модели (`.mar`): Убедитесь, что у вас есть обученная модель в папке `models/final_model` (выполните `dvc pull`, если нужно). Затем создайте архив:

```
    # Установите, если требуется
    pip install torch-model-archiver

    # Создайте директорию для архива
    mkdir -p model-store

    torch-model-archiver --model-name ai-detector --version 1.0 --handler serve/handler.py --extra-files "models/final_model/" --export-path model-store --force 
```
2. Соберите докер образ: `docker build -t ai-detector-serve:v1 .`
3. Запустите контейнер: `docker run -d --rm -p 8080:8080 -p 8081:8081 --name ai-detector-service ai-detector-serve:v1`
4. Сервис будет доступен по адресу `http://localhost:8080`
5. Сервис предоставляет один эндпоинт для предсказаний: `POST /predictions/ai-detector`
6. Тело запроса состоит из бинарных данных изображения (`.jpg`, `.png` и т.д.).
7. Пример запроса с `curl`:
```
curl -X POST http://localhost:8080/predictions/ai-detector -T /path/to/your/image.jpg
```
8. Успешный ответ (`200 OK`) будет содержать JSON-массив с одним объектом:
```
  {
    "label": "AI-generated",
    "confidence": 0.9912
  }
```